---
title: "线上实验五：实验分析"
date: "2024-06-14"
keywords: ["假设检验", "统计学", "实验灵敏度", "A/A测试", "干扰", "长期效应"]
series: "Causal-Inference"
---

本文是《Trustworthy Online Controlled Experiments》（中文版《关键迭代：可信赖的线上对照试验》）的第五部分（17-23章）主要内容的总结。

# 第17章：线上对照实验中的统计学知识

假设读者已经具备了假设检验（hypothesis testing）相关的统计基础知识。由于原文在这部分的讲解较为简略，本文将根据自身的理解对部分概念进行补充说明，以方便大家理解。如有错漏，欢迎联系指正。

### 1. Z检验和t检验的使用条件

#### Z检验
Z检验适用于以下几种情况：

- 样本服从正态分布且标准差已知。
- 样本量较大，即使总体标准差未知，但根据中心极限定理，样本近似服从正态分布。

#### t检验
t检验适用于数据近似正态分布，样本量较小（通常n < 30），且总体标准差未知的情况。

当样本量非常大时，t检验和Z检验的结果趋于一致。

### 2. 正态性假设的检验方法

在进行假设检验之前，验证数据是否符合正态分布非常重要。以下是几种常用的正态性检验方法：

#### 置换检验（Permutation Test）
置换检验是一种非参数检验方法，通过多次随机重排数据集来评估原假设的显著性。具体步骤如下：

1. 计算原始数据的检验统计量（如均值差异）。
2. 随机重排数据集多次（通常是1000次或更多），每次计算相应的检验统计量。
3. 比较原始数据的检验统计量与重排数据集的分布，计算p值。

置换检验主要用于两组数据比较的非参数检验，如Mann-Whitney U检验。它不依赖于数据的分布假设，非常适合小样本数据。

#### 常用的正态性检验方法
- **Shapiro-Wilk检验**：适用于小样本的正态性检验，假设检验统计量W接近1表明数据近似正态分布。
- **Kolmogorov-Smirnov检验**：适用于较大样本的正态性检验，比较样本分布与正态分布的差异。
- **Anderson-Darling检验**：一种改进的K-S检验，更加注重分布尾部的差异。

### 3. p值和置信区间

**p值**是指在原假设为真时，观察到检验统计量等于或更极端的概率。p值用于衡量检验结果的显著性，如果p值小于预设的显著性水平（通常为0.05），则拒绝原假设。

**置信区间**是指在一定置信水平下（如95%），包含总体参数的区间。置信区间提供了估计参数的范围，而不仅仅是单一值。

#### 关于置信区间的表述：
- 正确：置信区间表示在样本数据的基础上估计总体参数的范围。
- 正确：置信水平95%表示：在重复抽样的情况下，95%的置信区间将包含总体参数。
- 正确：如果在0.05显著性水平下拒绝原假设，那么95%的置信区间将不包含零。
- 错误：单次实验中，该参数有95%概率在这个区间里。
- 错误：95%的样本会落在置信区间内。

### 4. 多重检验

多重检验问题是指在进行多个统计检验时，增加了得到至少一个显著结果的概率，从而增加了第一类错误（即假阳性）的风险。为了解决这个问题，通常需要对显著性水平进行调整。

#### Bonferroni校正
假设我们有 $m$ 个独立检验，每个检验的显著性水平为 $\alpha$。未调整的情况下，至少有一个检验显著的概率为：
$$
P(\text{至少一个显著}) = 1 - P(\text{所有检验不显著}) = 1 - (1 - \alpha)^m \approx 1 - e^{-\alpha m} 
$$

为了控制总体的显著性水平在 $\alpha$ 内，Bonferroni校正将每个检验的显著性水平调整为 $\frac{\alpha}{m}$。因此，每个检验的p值需要与 $\frac{\alpha}{m}$比较，而不是与 $\alpha$ 比较。这虽然能有效控制第一类错误率，但在检验数量较多时，会显著降低检验的检出能力（即增加第二类错误的风险）。

#### 常用的替代方法
1. **霍尔姆校正（Holm-Bonferroni Correction）**：
   - 将所有p值按从小到大的顺序排序，记为 $p_{(1)}, p_{(2)}, ..., p_{(m)}$。
   - 依次比较每个p值与调整后的显著性水平 $\frac{\alpha}{m+1-i}$，从最小的p值开始，直到找到第一个不显著的p值。
   - 该p值及其后的所有p值均视为不显著。

2. **Benjamini-Hochberg校正（Benjamini-Hochberg Procedure）**：
   - 将所有p值按从小到大的顺序排序，记为 $p_{(1)}, p_{(2)}, ..., p_{(m)}$。
   - 找到最大的 $i$ 使得 $p_{(i)} \leq \frac{i}{m} \alpha$。
   - 该p值及其前面的所有p值均视为显著。

### 5. 费舍尔统合分析

费舍尔统合分析（Fisher's Method for Combining P-values）是一种将多个独立实验结果的p值合并成一个统计量的方法，尤其适用于整合同一假设的多次实验结果。这种方法在提高统计功效和降低假阳性率方面非常有效。

#### 费舍尔方法的步骤
1. **计算每个独立实验的p值**：运行每个独立实验，并计算其对应的p值 $p_1, p_2, \ldots, p_k$。
2. **合并p值**：使用公式 $\chi^2_{2k}  = -2 \sum_{j=1}^{k} \ln(p_j)$ 计算合并后的检验统计量。
3. **检验显著性**：比较 $\chi^2_{2k}$ 与自由度为 $2k$ 的卡方分布的临界值。

### 6. 混淆矩阵及其相关指标

**混淆矩阵**是评估分类模型性能的工具，包含以下指标：

1. **准确率（Accuracy）**: 正确预测的样本数占总样本数的比例。
    $$
    \text{Accuracy} = \frac{TP + TN}{TP + FP + FN + TN}
    $$
    
2. **精确率（Precision）**: 正确预测为正例的样本数占预测为正例的样本数的比例。
    $$
    \text{Precision} = \frac{TP}{TP + FP}
   $$
    适用场景：推荐系统、刑事死刑判决、垃圾邮件检测、优质贷款客户筛选。即允许一定程度的遗漏，但是检测为正的例子，有足够的理由认为真的为正。

3. **召回率（Recall）**: 正确预测为正例的样本数占实际为正例的样本数的比例。
    $$
    \text{Recall} = \frac{TP}{TP + FN}
    $$
    适用场景：医疗检测、欺诈交易检测。即允许有一定程度的误判，但尽量不能遗漏任何可能为正的情况。

4. **F1分数（F1 Score）**: 精确率和召回率的调和平均。
   $$
    \text{F1 Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
    $$

**ROC曲线和PR曲线**

- 定义决策规则： 
    $$
    \hat{y}_\tau(x) = \mathbb{I}(p(y=1 \mid x) \geq 1 - \tau)
    $$
- 假阳性（False Positive, FP）数：
    $$
    FP_\tau = \sum_{n=1}^N \mathbb{I}\left(\hat{y}_\tau\left(x_n\right)=1, y_n=0\right)
    $$
- 真阳性率（True Positive Rate, TPR）：
    $$
    TPR_\tau = p(\hat{y}=1 \mid y=1, \tau) = \frac{TP_\tau}{TP_\tau + FN_\tau}
   $$
- 假阳性率（False Positive Rate, FPR）：
    $$
    FPR_\tau = p(\hat{y}=1 \mid y=0, \tau) = \frac{FP_\tau}{FP_\tau + TN_\tau}
    $$

TPR对FPR的图称为接收者操作特征（ROC）曲线。在样本类别不平衡的情况下，使用ROC曲线评估模型性能可能会产生误导。具体来说，当正例（少数类）数量远小于负例（多数类）时，模型即使在大多数负例上表现良好（低FPR），也可能在正例上表现不佳（低TPR）。在这种情况下，仅看ROC曲线结果会过于乐观。

PR（精确率-召回率）曲线在评估不平衡数据集时更为合适。PR曲线通过展示精确率（Precision）和召回率（Recall）的权衡，能够更好地反映模型在少数类上的性能。PR曲线可能不是单调的，因此需要查看插值后的精确率（在至少达到某一召回率阈值时可以达到的最大精确率）。这种方法可以帮助我们更准确地理解模型在不平衡数据集上的表现。

ROC曲线下面积（AUC-ROC）和PR曲线下面积（AUC-PR）都是衡量分类模型性能的指标，数值越大表示模型性能越好。

# 第18章：方差估计和提高灵敏度：陷阱及解决方案

### 1. 常见陷阱
#### 绝对差异 vs. 相对差异
在实验中，相对差异（百分比变化）比绝对差异更为常见。相对差异定义为：
$$
\Delta\% = \frac{\Delta}{\bar{Y}^c} =  \frac{\bar{Y}^t-\bar{Y}^c}{\bar{Y}^c} 
$$
所以其方差应为：
$$
\text{Var}(\Delta\%) = \text{Var}\left(\frac{\bar{Y}^t}{\bar{Y}^c}\right)
$$

#### 比率指标
当分析单元与实验单元不同时（例如点击率CTR是点击数与页面浏览数的比率，而实验是按用户随机化的），使用简单的方差公式会导致偏差（不满足i.i.d假设）。此时的指标可表示为$M = \frac{\bar{X}}{\bar{Y}}$。

**Delta方法**：假设有一个随机变量向量 $\mathbf{X} = (X_1, X_2, ..., X_n)$，以及一个连续函数 $g(\mathbf{X})$。如果我们知道 $\mathbf{X}$ 的协方差矩阵为 $\Sigma$，则 $g(\mathbf{X})$ 的方差可近似为：

$$
\text{Var}(g(\mathbf{X})) \approx \nabla g(\mu)^T \Sigma \nabla g(\mu)
$$

其中 $\mu$ 是 $\mathbf{X}$ 的均值向量，$\nabla g(\mu)$ 是函数 $g$ 在 $\mu$ 处的梯度。

计算过程：样本均值$\bar{X}$ 和 $\bar{Y}$ 的协方差矩阵为：
   $$
   \Sigma = \begin{pmatrix}
   \text{Var}(\bar{X}) & \text{Cov}(\bar{X}, \bar{Y}) \\
   \text{Cov}(\bar{X}, \bar{Y}) & \text{Var}(\bar{Y})
   \end{pmatrix}.
   $$

应用delta方法估计可得   
$$
\begin{align*}
   \text{Var}\left(\frac{\bar{X}}{\bar{Y}}\right) &\approx \left( \frac{1}{\bar{Y}}, -\frac{\bar{X}}{\bar{Y}^2} \right) \Sigma \begin{pmatrix}
   \frac{1}{\bar{Y}} \\
   -\frac{\bar{X}}{\bar{Y}^2}
   \end{pmatrix}\\
   &=\frac{1}{\bar{Y}^2} \text{Var}(\bar{X}) - 2 \frac{\bar{X}}{\bar{Y}^3} \text{Cov}(\bar{X}, \bar{Y}) + \frac{\bar{X}^2}{\bar{Y}^4} \text{Var}(\bar{Y})
\end{align*}
   $$
当指标不能写成用户层面指标比率时，可以考虑自展法（bootstrap）：通过有放回的采样过程，多次模拟估计方差。虽然需要较大算力，但它非常强大且广泛适用，补充了delta方法。

#### 离群值
离群值对方差的影响会比对均值的影响更大，从而影响统计量的显著性。实践中可以通过设定合理的阈值以有效去除离群值。

### 2. 提高灵敏度
这里主要讨论通过减小方差来提高灵敏度的方法。

- **创建方差较小的评价指标。** 例如，使用搜索者数量代替搜索次数可以减少方差，转换率比购买金额的方差更小，从而减少所需样本量。
- **通过添加阈值、二元化和对数转化来改变指标。** 对于严重的长尾指标，特别是当可解释性不是特别重要时，可以考虑使用对数转化。
- **触发分析（详见第20章总结）。** 可以去除未受影响用户引入的噪音 。
- **分层采样、控制变量法和CUPED。** 分层采样通过将样本划分为不同层并分别采样，再合并结果以减少方差。控制变量法类似，但使用协变量作为回归分析的参数。CUPED利用实验前的数据作为协变量纳入回归模型，提高统计功效。
- **选择颗粒度更精细的随机化单元。**
- **设计配对实验。** 用户同时看到实验组和对照组，以消除个体间的差异。
- **共享对照组。** 合并对照组形成一个大的共享对照组，提高所有实验的功效。

# 第19章：A/A测试

### 1. A/A测试的目的
- **控制I类错误**：通过运行A/A测试，可以查出问题，如指标的方差计算可能不对，或者正态性的假设不成立。
- **评估指标的波动性**：通过A/A测试的数据，可以确定随着用户数量增加，指标的方差如何变化（如均值方差是否下降）。
- **确保实验组和对照组用户无偏差**：A/A测试有助于识别平台层面引入的偏差。
- **比较数据和系统记录**：A/A测试可以验证关键指标是否与系统记录一致。
- **估计方差以计算统计功效**：A/A测试提供的指标方差有助于确定A/B测试所需的运行时间。

#### 常见案例分析
- **案例1：分析单元和随机化单元不一致**：例如，CTR有两种计算方法，总点击数除以总页面浏览量使得方差计算困难；而平均所有用户的CTR，在有离群值时更为准确。
- **案例2：Optimizely鼓励在结果统计显著时停止实验**：窥探和提前停止实验会导致许多假阳性。

### 2. 如何运行A/A测试
首先我们证明A/A测试中，p值在零假设下是均匀分布的。

假设我们进行一个双边检验，其p值定义为：

$$
p = P(T \geq T_{\text{obs}} \mid H_0)
$$

其中 $T_{\text{obs}}$ 是观测到的检验统计量的值。检验统计量为 $T$，它的分布在 $H_0$ 下是已知的。所以：

$$
p = 1 - F_T(T_{\text{obs}})
$$

从而有

$$
\begin{align*}
P(p < \alpha) &= P(F_T(T_{\text{obs}}) > 1-\alpha) \\
& = 1- P(T_{\text{obs}} \le F_T^{-1}(1-\alpha))\\
& = 1- F_T\big( F_T^{-1}(1-\alpha)\big) = \alpha.
\end{align*}
$$

这里我们证明了p值的累积分布函数(CDF)是线性的，从而证明了p值在零假设下是均匀分布的。

上述结论告诉我们，如果多次A/A测试计算出来的p值的分布离均匀分布很远，那么系统可能存在问题。为了节约成本，可以通过重播上周的数据，将用户分成两组，然后对每个感兴趣的指标生成p值并画成直方图。然后通过诸如K-S测试来检验是否服从均匀分布。

### 3. A/A测试失败时
常见的p值非均匀分布分析：

1. **分布偏斜且明显不均匀**：通常是指标方差估计问题，例如分析单元和随机化单元不一致而违反独立性假设。或者检查最小样本量是否满足要求。
2. **在p值0.32附近有许多观测值**：表明可能存在离群值问题。
3. **分布中的一些点有很大的间隙**：可能是因为指标的差异是离散的，导致p值只有几种取值。

# 第20章：以触发来提高实验灵敏度

### 1. 触发示例
触发为实验者提供了一种通过过滤掉不可能受到实验影响的用户所产生的噪音来提高灵敏度（统计功效）的方法。当用户所在的变体在系统或用户行为上与其他变体（虚拟事实）的结果可能存在差异时，会触发该用户进入实验分析。

触发示例包括：

- 分析仅受影响用户的数据，如地理位置或特定功能的改动。
- 条件曝光和实验覆盖范围变化的用户。

### 2. 实践
- 最优触发条件是只对有差异的用户进行触发分析。然而，实际中有时会采取保守触发，包含更多用户但不影响分析有效性，只是降低了统计功效。
- 计算触发用户的实验效应时，必须将其稀释到整个用户群。比率指标可能会导致辛普森悖论。

令$\omega$表示总体用户，$\theta$表示被触发的用户，$C$和$T$分别表示控制组和处理组，$N$表示用户数量。
定义$\Delta_{\theta} = M_{\theta T} - M_{\theta C}$，即触发用户的绝对效应。
定义$\delta_{\theta} = \frac{\Delta_{\theta}}{M_{\theta C}}$，即触发用户的相对效应。
触发率为触发用户占总体用户的百分比，可由处理组、控制组或两者之和计算出，如
$$
\tau = \frac{N_{\theta C} + N_{\theta T}}{N_{\omega C} + N_{\omega T}}.
$$

公式 $\frac{\Delta_{\theta}}{M_{\omega C}} \cdot \tau$ 可用来稀释影响。

- 为了确保触发的可信度，应该进行以下检查：
1. 样本比例不匹配（SRM）。
2. 补充分析，为未触发的用户生成实验看板，若A/A实验结果显著不同，表明触发条件可能有误。


### 3. 常见陷阱
- 难以推广在微小细分上运行的实验。如果你要改善总体用户指标，那么重要的是实验的稀释价值（能否推广到更多用户）。
- 未能在实验的剩余时间正确触发已触发的用户。一旦用户被触发，分析必须包含他们后续的行为，否则会低估处理效应。
- 虚拟事实日志记录对性能的影响：（1）记录每个模型用时；（2）运行A/A'/B实验，若A和A'显著不同，发出虚拟事实日志记录产生影响的警报。

# 第21章：样本比例不匹配与其他可信度相关的护栏指标

### 1. SRM 的原因
SRM 的原因多种多样，包括用户随机化过程有漏洞、数据管线问题、残留效应和糟糕的触发条件等。

### 2. 调试SRM
当样本比例指标的$p$值很低时，应假设系统中存在漏洞并进行调试。调试SRM很困难，通常需要内部工具来帮助调试，例如验证在随机化时机点或触发时机点的上游没有区别，验证实验变体的分配设置是正确的，检查数据处理管线的各个阶段（启发式方法剔除机器人），用户细分群组的样本比率。

除了SRM，原文还提到了其他与可信度相关的护栏指标，感兴趣的读者可阅读原文了解更多细节。

# 第22章：实验变体之间的泄露和干扰

### 1. 干扰的定义
Rubin因果模型中的一个关键假设是个体处理稳定性假设（SUTVA），即每个实验单元的行为不受其他单元变体分配的影响。可表示为
$$
Y_i(z) = Y_i(z_i)
$$
这里i表示实验单元编号，$z = (z_1,\cdots,z_n)$是n个实验单元的变体分配向量。

干扰被定义为违反SUTVA的情况，也称为变体间的泄漏或溢出。

### 2. 干扰的类型
如果两个实验单元是社交网络上的朋友或他们同时访问了同一个物理地点，那么他们是直接关联的。两个单元可能会因为特定的隐性变量或共享资源而存在间接关联。

- **直接关联**：如社交网络和通信工具等，实验组的变动也会影响对照组用户，导致差别变小。
- **间接关联**：如Airbnb租房、Uber/Lyft打车、eBay拍卖和广告活动等，新算法可能使实验组更活跃，从而减少对照组的资源，使得两者的差别被高估。如果采用比用户颗粒度更精细的实验单元如网页，则同一用户可能有实验组和对照组的混合体验，从而低估了实验效果。

更多例子和细节讲解可以参看原文。

### 3. 解决方案

1. **经验法则**：界定可能产生溢出的行为，仅当这些行为被实验影响时才关注干扰。例如社交网络中发送/回复消息数，创作者/帖子总数，点赞/评论总数等，可以显示对下游的影响。

- 优点：经验法则方法相对容易实施，因为只需一次性建立生态系统价值，就可应用于任何伯努利随机实验。它比其他方法更敏感，因为它依赖伯努利随机化来测量下游指标的显著影响。
- 局限性：这种方法本质上只是一个近似值，可能不适用于所有情境。

2. **隔离**：
   - **划分共享资源**：如果共享资源导致干扰，可以按变体划分资源。
   - **基于地理位置的随机化**：如果干扰发生在地理上接近的单元间，可以按地区随机化。但各地域样本量会有不同，导致更大的方差，更低的统计功效。
   - **基于时间的随机化**：利用时间制造隔离，可以在任何时间给予所有用户同一策略。注意通过配对t检验或协变量校正，合理利用时间效应以降低方差。
   - **网络群组随机化**：在社交网络上，根据结点之间相互干扰的可能性构建“群组”，并按群组独立随机分配。限制：（1）社交网络关联图是稠密的，仍有大量的群组间关联。（2）有效的实验样本量很小，需要做方差-偏差之间的权衡。
   
   可以通过改进为**以网络焦点为中心的随机化**来解决这些问题。此时每个群组有一个焦点和相邻点，允许对焦点和相邻点单元分别决定实验变体的分配，从而达到更好的隔离，更小的方差。

3. **边级别分析**：通过对比不同类型的边级别发生的交互（例如有向图$C/T\to C/T$），可以帮助理解重要的网络效应。

# 第23章：测量实验的长期效应

### 1. 什么是长期效应

长期效应被定义为实验的渐近效应，通常需要超过3个月的时间，或者基于曝光次数（例如，使用新功能至少10次的用户的实验效应）。

对于大多数实验，短期效应（短时间内测量到的实验效应）是稳定的并且能够推广到长期效应。但某些情况下，两者有所不同。

### 2.短期效应和长期效应可能不同的原因

- **用户的习得效应**：用户在学习并适应变化的过程中会改变他们的行为。例如，频繁的产品崩溃会使用户决定放弃产品。
- **网络效应**：实验变体之间的互相影响可能导致短期效应的估计偏差。双边市场、招聘市场、推荐系统等，初始表现良好，但长期均衡可能较低。
- **延迟的体验和评估**：用户可能需要一段时间来体验到整个实验改动。例如，旅游的线上预订和实际感受之间的时间差，年度合同的决策。
- **生态系统变化**：随着时间推移，生态系统中的变化会影响用户对实验的反应，例如新功能发布、季节性因素、竞争格局变化、政策调整、概念漂移和软件性能下降。

### 3. 为什么要测量长期效应

- **归因**：在数据驱动文化中，实验结果用于跟踪团队目标和绩效，并可能将实验收益纳入长期财务预测。
- **机构经验**：了解短期与长期效果的区别及其原因，为后续改进和迭代提供洞察。
- **可推广性**：测量某些实验的长期效应并将结论推广到其他实验。

### 4. 长期运行的实验
最简单的测量长期效应的方法就是长期运行实验，然后定期测量实验效应。第一个测量值为短期效应，最后一个测量值被认为是长期效应。

- **归因**：实验效应稀释导致最后一个测量值无法代表真正长期效应的原因：
  1. 用户可能在实验期间使用多个设备或入口，实验只能捕捉到一部分使用情况。
  2. 基于Cookies随机化，Cookies可能因用户行为或浏览器问题而变化，用户可能在实验组和对照组之间切换。
  3. 存在网络效应且无法完全隔离各变体，实验效应可能会“泄漏”到对照组。
- **幸存者偏差**：如果实验组和对照组的生存率不同，测量的实验效应会有幸存者偏差，触发SRM警报。
- **与其他新功能的互动**：在长期实验运行期间，可能有其他功能上线，这些新功能可能与正在测试的特定功能交互并侵蚀实验效果。
- **时间外推效应**：如果实验期间的基本人群或外部环境发生变化（如季节性），我们无法直接比较这些结果。

### 5. 长期运行实验的替代方法

1. **群组分析**：选择一个稳定的用户群，仅分析该群的短期和长期效应。这可以有效解决稀释和幸存者偏差问题，但需要确保群组能代表总体人群。

2. **后期分析**：在实验运行一段时间（T）后关闭实验，然后在时间T和T+1期间测量实验组和对照组用户的差异。如果无法关闭实验组，可以将实验组发布给所有用户。
    - **用户习得效应**：用户适应并了解了产品改动，例如广告加载量增加对用户点击广告的影响。
    - **系统习得效应**：系统在实验期间“记住”了信息，例如个性化设置、取消订阅等。
    这种方法可以根据系统参数测量习得效应，然后从新的短期实验中外推出预期的长期效应。存在稀释和幸存者偏差，但习得效应单独测量后可尝试调整以解决稀释问题，或结合群组分析方法使用。

3. **时间错开实验**：同时运行两个错开开始时间的版本，通过比较两者的差异来确定长期效果。这减少了季节性等外部因素的影响，但需要确保两个版本的变化仅限于时间上的差异。

4. **留出和反转实验**：保留部分用户在对照组中以观察长期效应。反转实验是将新功能发布给全部用户后再将部分用户放回对照组。这可以减少处理效果稀释的问题，但需要确保转换过程不会影响用户体验。

#
### 参考文献

- Kohavi, Ron, Diane Tang, and Ya Xu. *Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing (关键迭代：可信赖的线上对照试验)*. Cambridge University Press, 2020.

### 留言区
欢迎在下方留言讨论。如果您无法输入评论，请确保您已登录 GitHub 账号。

{{< include ../../_includes/utterances.html >}}
