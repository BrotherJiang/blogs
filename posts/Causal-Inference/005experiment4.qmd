---
title: "线上实验四：实验平台搭建"
date: "2024-06-03"
keywords: ["随机化单元", "实验放量", "实验分析"]
series: "Causal-Inference"
---

本文是《Trustworthy Online Controlled Experiments》（中文版《关键迭代：可信赖的线上对照试验》）的第四部分（12-16章）主要内容的总结。

# 第12章：客户端实验

本章通过比较服务器端和客户端的差异，详细分析了这些差异对不同终端实验的潜在影响。感兴趣的读者可以参阅原文以获取更多细节。

# 第13章：工具化日志记录

本章通过对比客户端和服务器端的日志记录侧重点，详细探讨了如何在不同系统中记录以跟踪用户行为和系统性能。感兴趣的读者可以参阅原文以获取更多细节。

# 第14章：选择随机化单元

### 1. 颗粒度
例如，网站有以下自然的粒度：页面级、会话级、用户级。

在选择粒度时，有两个主要问题需要考虑：

1. **用户体验的一致性有多重要？**
   用户越会注意到的实验改动，随机化的过程使用更粗糙的颗粒度以确保用户体验的一致性就越重要。
2. **哪些指标很重要？**
   较细颗粒度的随机化创建了更多单元，因此指标均值的方差较小，实验将有更大的统计功效来检测较小的变化。

注意：

1. 如果新功能跨越该颗粒度级别起作用，则不能使用该颗粒度级别进行随机化。比如个性化的新功能会使页面之间不独立。
2. 跨越颗粒度级别而计算的指标不能用于测量实验结果。
3. 将用户曝光在不同的实验变体中可能会违反个体处理稳定性假设（SUTVA）。

### 2. 随机化单元和分析单元
建议选择与关注的指标的分析单元相同（或更粗糙的颗粒度）的随机化单元。

随机化单元与分析单元相同时，因为单元之间的独立性假设在实践中是合理的，所以更容易正确地计算出指标的方差。

如果随机化单元比分析单元更粗，则需要使用更复杂的分析方法，如自展法（bootstrap）或Delta方法。在这种情况下，实验结果可能因为一个用户ID而偏斜，此时需考虑限制任何单个用户可能对更精细的颗粒度的指标的影响，或切换到基于用户的指标。

### 3. 用户级别随机化
用户级别随机化是最常见的，因为它避免了用户体验的不一致，并且可以长期测量用户留存等。

- **登录ID**：已登录ID不仅在平台间特别稳定，而且在时间纵向上（长时间）也很稳定。
- **匿名用户ID**：如cookie。这些ID在跨平台时不稳定。
- **设备ID**：不具备跨设备或跨平台的一致性，但通常在同一设备上长时间内稳定。

# 第15章：实验放量：权衡速度、质量与风险

### 1. 什么是放量
逐步放量是控制新功能曝光给用户的过程，以控制发布带来的未知风险。实验出现明显问题，会快速缩量为零，以减少对用户的影响。

### 2. SQR逐步增加框架
为什么要进行线上对照实验：
- 测量实验组变体 100% 发布的影响和投资回报率（Return-On-Investment，ROI）。
- 通过最小化实验对用户和业务的损害及成本来降低风险。
- 学习用户反馈，理想情况下按用户细分群体来识别潜在的漏洞并为未来的计划提供参考。

放量时，需权衡速度、质量和风险（Speed, Quality and Risk, SQR）。

### 3. 四个放量阶段
最大统计功效放量（Maximum Power Ramp, MPR）：若实验有$x\%$的流量且有n个变体，则每个变体获得$\frac{x}{n}\%$的流量。

#### 第一放量阶段：MPR之前
此阶段旨在降低风险，通过逐步增加曝光量确保安全性：
1. 创建测试人群环，从内部员工、Beta用户到数据中心，逐步曝光新功能。
2. 自动增加流量，直到达到所需配额。
3. 实时监控关键护栏指标，快速判断实验风险。

#### 第二放量阶段：MPR
MPR阶段专注于测量实验影响，通常保持一周时间，以捕捉时间因素的影响。如果不存在初始或新奇效应，则进入下一阶段。

#### 第三放量阶段：MPR之后
通过逐步增加流量至100%，解决任何运营问题，确保系统能够处理高峰期的负载。

#### 第四放量阶段：长期留出阶段或重复实验
长期留出（部分用户长时间体验不到实验改动），以观察长期影响。这个阶段主要用于以下情况：

1. 确认实验的长期影响，避免初始或新奇效应对结果的干扰。
2. 早期指标显示出影响但关键指标是长期指标，如月留存率。
3. 运行更久以减少方差。

# 第16章：规模化实验分析

本章可视作数据分析主要步骤的简介，有很多数据科学相关资料可作为补充阅读。

### 补充阅读材料

#### 代码实践
- 《Python for Data Analysis》（中文版《利用Python进行数据分析》）
- 《Machine Learning for Hackers》（中文版《机器学习实用案例解析》）

#### 数据处理
- 《Machine learning design patterns》

#### 数据可视化
- 《Storytelling with Data》（中文版《用数据讲故事》）

#### 数据科学
- 《Approaching (Almost) Any Machine Learning Problem》

### 1. 数据处理
原文提及的主要数据处理步骤包括：数据排序和分组，清洗数据，和扩展数据。更多技巧细节推荐阅读上述材料。

### 2. 数据计算
数据计算有两种常见的方法：

1. 先计算每个用户的统计信息，然后将其连接到一个将用户映射到实验的表格。这样可以将每个用户的统计信息用于总体业务报告。
2. 将每个用户指标的计算与实验分析完全集成在一起，每个用户的指标是按需进行计算的。通过共享指标和细分群的定义，以确保不同管线之间的一致性。

### 3. 结果汇总和可视化
在结果汇总和可视化阶段，需要展示关键测试结果，全方位展示相关指标，显示相对变化以及是否具有统计显著性。

为了真正实现实验的规模化，应确保所有相关人员都能够访问分析看板，获取关注指标的信息。当实验产生负面影响时，平台应能够强制实验所有者在实验放量前与指标所有者进行对话。

### 参考文献

- Kohavi, Ron, Diane Tang, and Ya Xu. *Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing (关键迭代：可信赖的线上对照试验)*. Cambridge University Press, 2020.

### 留言区
欢迎在下方留言讨论。如果您没有看到评论框，请确保您已登录 GitHub 账号。

{{< include ../../_includes/utterances.html >}}